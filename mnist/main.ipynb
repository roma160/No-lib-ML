{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST dataset training\n",
    "The algorithms is taken from [3B1B](https://youtu.be/aircAruvnKk)\n",
    "\n",
    "The TS library is used only to download the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libs and dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\user\\projects\\python\\LearningML\\NoLibImpl\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Typing\n",
    "from typing import Callable, Union\n",
    "import numpy.typing as npt\n",
    "\n",
    "# Structure\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset mnist (C:\\Users\\mario\\.cache\\huggingface\\datasets\\mnist\\mnist\\1.0.0\\fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 333.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "dataset = load_dataset(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;PIL.PngImagePlugin.PngImageFile image mode=L ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;PIL.PngImagePlugin.PngImageFile image mode=L ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;PIL.PngImagePlugin.PngImageFile image mode=L ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;PIL.PngImagePlugin.PngImageFile image mode=L ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;PIL.PngImagePlugin.PngImageFile image mode=L ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  <PIL.PngImagePlugin.PngImageFile image mode=L ...      5\n",
       "1  <PIL.PngImagePlugin.PngImageFile image mode=L ...      0\n",
       "2  <PIL.PngImagePlugin.PngImageFile image mode=L ...      4\n",
       "3  <PIL.PngImagePlugin.PngImageFile image mode=L ...      1\n",
       "4  <PIL.PngImagePlugin.PngImageFile image mode=L ...      9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting the dataset obj to the pd.DataFrame (to make the work easier)\n",
    "_train, _test = dataset.values()\n",
    "ds_train = pd.DataFrame(_train)\n",
    "ds_test = pd.DataFrame(_test)\n",
    "\n",
    "ds_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data preparation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preparation_pipeline(ds: pd.DataFrame) -> None:\n",
    "    # (PillowPNG -> np.array) => normalizing (unint8 -> float32) => flattening input\n",
    "    ds[\"image\"] = ds[\"image\"].apply(lambda el: np.array(el).reshape((-1,)) / 255.)\n",
    "    # Hot-encoding output\n",
    "    ds[\"label\"] = ds[\"label\"].apply(lambda el: 1. * (np.arange(10) == el))\n",
    "    # Renaming the columns\n",
    "    ds.rename({\"image\": \"x\", \"label\": \"y\"}, inplace=True)\n",
    "\n",
    "\n",
    "# Applying pipeline\n",
    "for ds in [ds_train, ds_test]:\n",
    "    preparation_pipeline(ds)\n",
    "\n",
    "# Shuffling with pd method sample\n",
    "ds_train = ds_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "ds_train.iloc[0][\"image\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent formulas:\n",
    "### Some reference\n",
    "<img src=\"./images/ref1.png\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recurent formulas are the initial bounds of our model, which we are then using to derive the training steps.\n",
    "\n",
    "Basically, we could define our model as $ F(x) = y $, but, as it must be more complex than this, we make some expansion.\n",
    "\n",
    "As we are dealing with the neural network, it is much better to store weights between two layers in a 2d matrix:\n",
    "$$ \\displaystyle\n",
    "W^{(l)}_{m\\leftarrow n} = \n",
    "\\begin{pmatrix}\n",
    "    w^{(l)}_{11} & w^{(l)}_{12} & \\dots & w^{(l)}_{1n} \\\\\n",
    "    w^{(l)}_{21} & w^{(l)}_{22} & \\dots & w^{(l)}_{2n} \\\\\n",
    "        \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    w^{(l)}_{m1} & w^{(l)}_{m2} & \\dots & w^{(l)}_{mn} \\\\\n",
    "\\end{pmatrix},\n",
    "$$\n",
    "Where $ w^{(l)}_{ij} $ denotes weight from neuron $i$ to neuron $j$ in layer $l$.\n",
    "Lets call this $ W^{(l)} $ -thing, which is essentially symbolices the bundle of weights between two layers, *the weights layer number $l$*.\n",
    "\n",
    "As we are approaching matrix math, let us denote **($*$)** as a **matrix multiplication** and **($\\cdot$)** as **element-wise multiplication** (and as this operation doesn't affects the dimentionality, often this dot could be just omited ðŸ™ƒ). Please also note, that having the element-wise multiplication gives us the right to define in the same way the **element-wise division**.\n",
    "\n",
    "Let also $W$ would be the array, holding all of these matrixes:\n",
    "$$ W = [\\;\\underbrace{W^{(0)}, W^{(1)}, \\dots, W^{(L-2)}}_{L-1}\\;] $$\n",
    "<div></div>\n",
    "\n",
    "But now lets define the neuron function and its output.\n",
    "Let $raw^{(l)} = [raw^{(l)}_1, raw^{(l)}_2, \\dots, raw^{(l)}_i, \\dots, raw^{(l)}_n]$\n",
    "would be the input, that goes to the neuron $i$ in layer $l$.\n",
    "And let the $A_f^{(l)}: \\mathbb{R}\\rightarrow \\mathbb{R}$ - an activation function of neurons in the layer $l$ and $A_d^{(l)}$ - its derivative.\n",
    "Okay, now we are finally able to define the output of the neuron layer $l$ as $out^{(l)} = [out^{(l)}_1, out^{(l)}_2, \\dots, out^{(l)}_i, \\dots, out^{(l)}_n]$, where $out^{(l)}_i$ denotes output of $i$ -th neuron.\n",
    "\n",
    "It is also quite a crutial thing not to mess up the indexes. And so, please note that while let we have $L$ layers of neurons, there are only $L-1$ \"weighted connections\" between them, thus we have only L-1 elements of $W$ array respectively. And this means that there are also $L$ inputs/outputs of the each neuron layer, which we would also store in one list, following the $W$ model:\n",
    "$$ raw = [\\;\\underbrace{raw^{(0)}, raw^{(1)}, \\dots, raw^{(L-1)}}_{L}\\;] $$\n",
    "$$ out = [\\;\\underbrace{out^{(0)}, out^{(1)}, \\dots, out^{(L-1)}}_{L}\\;] $$\n",
    "<div></div>\n",
    "\n",
    "Taking the things said before into account, we are finally could define the \"function\" $F$:\n",
    "$$\n",
    "F: \\begin{cases}\n",
    "out^{(0)} = x; \\\\\n",
    "raw^{(l)} = W^{(l-1)} * out^{(l-1)} + b^{(l-1)}; \\\\\n",
    "out^{(l)} = A_f^{(l)}(raw^{(l)}); \\\\\n",
    "y = out^{(L-1)};\n",
    "\\end{cases}\n",
    "$$\n",
    "(Where $b^{(l)}$ is a bias of $l$ -th layer, and has the same dimentionality as $W^{(l)} * out^{(l-1)}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layers class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ActivationFunction:\n",
    "    \"\"\"\n",
    "        This class is used to store information about the activation function.\n",
    "        (In our case we store the function, its derivative and name).\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "\n",
    "    # The function callable\n",
    "    # (Pay close attention to the input and output types: \n",
    "    #   we are applying function elementwise)\n",
    "    f: Callable[[np.ndarray], np.ndarray]\n",
    "\n",
    "    # The derivative callable of function\n",
    "    d: Callable[[np.ndarray], np.ndarray]\n",
    "\n",
    "    # This thing would make our live easier, debugging the model\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "\n",
    "class Functions:\n",
    "    \"\"\"\n",
    "        Singleton thing to store existing activation functions\n",
    "    \"\"\"\n",
    "\n",
    "    # Lambda notation used not to mess up too much the code\n",
    "    sigmoid = ActivationFunction(\n",
    "        \"sigmoid()\",\n",
    "        lambda x: 1 / (1 + np.exp(-x)),\n",
    "        # https://math.stackexchange.com/questions/78575/derivative-of-sigmoid-function-sigma-x-frac11e-x\n",
    "        lambda x: (lambda o: o*(1-o)) (1 / (1 + np.exp(-x)))\n",
    "    )\n",
    "\n",
    "    relu = ActivationFunction(\n",
    "        \"relu()\",\n",
    "        # Attention: we are multiplying float with bool \n",
    "        # https://stackoverflow.com/questions/18601484/subtract-boolean-from-float-in-python\n",
    "        lambda x: x * (x >= 0),\n",
    "        lambda x: 1. * (x > 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sigmoid()', 0.6224593312018546)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing our brand-new abstractions:\n",
    "str(Functions.sigmoid), Functions.sigmoid.f(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINALLY WE HAVE THE NEURAL MODEL CLASS!\n",
    "\n",
    "class Model:\n",
    "    \"\"\"\n",
    "        This thing would help us to build an abstraction from the arrays of arrays of arrays...\n",
    "    \"\"\"\n",
    "\n",
    "    class WeightsFilling(Enum):\n",
    "        \"\"\"\n",
    "            Enum storing available types of filling (in __init__ func) our weights\n",
    "        \"\"\"\n",
    "        RANDOM = 0\n",
    "        ZEROS = 1\n",
    "        ONES = 2\n",
    "\n",
    "    def __init__(self, \n",
    "        shape: tuple[int],\n",
    "        activations: list[ActivationFunction] = list(),\n",
    "        fill_type: Union[WeightsFilling, list[WeightsFilling]] = list()\n",
    "    ):\n",
    "        \"\"\"\n",
    "            :param shape: number of \"neurons\" is each of the network layers\n",
    "                (actually will be used to specify the matrix dimentionality)\n",
    "            \n",
    "            :param activations: activations that are used in each network layer\n",
    "\n",
    "            :param fill_type: types of filling for each of the \"weights layers\"\n",
    "                (bundle of weights inbetween layers)\n",
    "        \"\"\"\n",
    "\n",
    "        self.shape = shape\n",
    "        self.L = len(shape)\n",
    "\n",
    "        # Formatting activation parameter\n",
    "        if not activations:\n",
    "            activations = np.full(self.L - 1, Functions.sigmoid)\n",
    "        else:\n",
    "            activations = np.array(activations)\n",
    "        \n",
    "        # Formatting fill_type parameter\n",
    "        if isinstance(fill_type, self.WeightsFilling):\n",
    "            fill_type = [fill_type] * (self.L - 1)\n",
    "        elif not fill_type:\n",
    "            fill_type = [self.WeightsFilling.RANDOM] * (self.L - 1)\n",
    "        \n",
    "        # Activation of layers\n",
    "        self.a = activations\n",
    "        # Weights layers\n",
    "        self.w = np.empty_like(activations, dtype=np.ndarray)\n",
    "        # Biases\n",
    "        self.b = np.empty_like(activations, dtype=np.ndarray)\n",
    "\n",
    "        # Here we are doing the weights filling, in correspondence with the fill_type\n",
    "        for i in range(self.L - 1):\n",
    "            if fill_type[i] is self.WeightsFilling.RANDOM:\n",
    "                self.w[i] = np.random.rand(shape[i], shape[i+1])\n",
    "                self.b[i] = np.random.rand(shape[i+1])\n",
    "            \n",
    "            elif fill_type[i] is self.WeightsFilling.ONES:\n",
    "                self.w[i] = np.ones(shape[i], shape[i+1])\n",
    "                self.b[i] = np.ones(shape[i+1])\n",
    "            \n",
    "            elif fill_type[i] is self.WeightsFilling.ZEROS:\n",
    "                self.w[i] = np.zeros(shape[i], shape[i+1])\n",
    "                self.b[i] = np.zeros(shape[i+1])\n",
    "    \n",
    "    # Again, the thing that would help us to debug the entire notebook\n",
    "    def __str__(self):\n",
    "        ret = f\"NN model of shape {self.shape}\\n\"\n",
    "        for i in range(self.L - 1):\n",
    "            ret += f\"Layer {i}: a={self.a[i]}, w={self.w[i].shape}, b={self.b[i].shape}\\n\"\n",
    "        return ret\n",
    "\n",
    "# no neurons? ðŸ˜“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN model of shape (3, 2, 1)\n",
      "Layer 0: a=sigmoid(), w=(3, 2), b=(2,)\n",
      "Layer 1: a=sigmoid(), w=(2, 1), b=(1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = Model((3, 2, 1))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward and backward propagations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we would derive the steps, that will allow us to train our network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivations:\n",
    "\n",
    "Basically, right now we only have a model, that tells us how to organise the data of neural network. But yet we have not talked about how to assign this data in such a way, that network would do the thing we want it to do. So, lets try to find a way to make it.\n",
    "\n",
    "You may have already spotted in the code, that we preassing the values of the weight with some random mess/zeros/ones. Obviously, this is not enough to make our model solve thr problems. Thus, we need to determine how to alter this preassigned values in order to *teach* the network.\n",
    "\n",
    "Right now we do not have anything, that would tell how much and in which direction to change the weights, so lets define something. Let the $ C $ would be the error-metric. It would tell us, how much the model mistaken, answerring the question: the larger the $ C $ value, the more wrong it is. If the network answerred the question perfectly, then let the $ C $ would be $ 0 $.\n",
    "\n",
    "Great, now we could rephrase our task as *find model parameters, such that the $ C $ on each of the possible task would be minimal*.\n",
    "\n",
    "And, hey, look what we would have, if we consider function $ C(p) $ that returns sum of errors of model with parameters $ p $ along all of the existing tests. Solving the task would mean *finding the roots of $ C(p) $*. We are now still closer to the real analysis.\n",
    "\n",
    "Okay, so how can we find the roots of some abstract function $ C(p) $? Of course, using the [Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method) ([link #2](https://youtu.be/-RdOwhmqP5s)). I will not explain its idea here, as there are a lot of people that done this thing much better than I can. But an essential thing to know is that we would need to compute the derivatives of the $ C(p) $ with respect to each of the network parameters, which will then be used to alter these parameters just the right amount, so that in the end we would get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we still have not defined the $ C(p) $. Firstly, lets say, that we are now considering the one individual test, and we want our network to perform best on it. Then\n",
    "\n",
    "$$ C(p) = C = \\sum_i{(y_i - y_i^*)^2} = |y - y^*| $$\n",
    "\n",
    "(where $ y $ - the answer vector of the network, and $ y^* $ - the right answer vector)\n",
    "would fully satisfy our description.\n",
    "\n",
    "Lets start derivating!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dC/dy:\n",
    "This thing is mostly obvious: \n",
    "\n",
    "$$ \\displaystyle\n",
    "\\frac{dC}{dy_i} = \\frac{d\\sum_j{(y_j - y_j^*)^2}}{dy_i} \n",
    "    = \\frac{d(y_0 - y_0^*)^2}{dy_i} + \\frac{d(y_1 - y_1^*)^2}{dy_i} + \\dots + \\frac{d(y_i - y_i^*)^2}{dy_i} + \\dots\n",
    "$$\n",
    "\n",
    "$$ \\displaystyle\n",
    "\\frac{dC}{dy_i} = 0 + 0 + \\dots + \\frac{d(y_i - y_i^*)^2}{dy_i} + \\dots\n",
    "$$\n",
    "<div></div>\n",
    "\n",
    "$$ \\displaystyle \\large\n",
    "\\frac{dC}{dy_i} = 2(y_i - y_i^*);\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dout(l)/dout(l-1)\n",
    "\n",
    "Actually, $ y_i $ is an output of last neuron layer, so, we have just found $ \\displaystyle \\frac{dC}{dout^{(L)}} $. But, to know the derivatives with respect to other neurons and their weights, we need to find a way to jump to previous layer. Lets recall our recurrent formula:\n",
    "\n",
    "$$ \\displaystyle\n",
    "out^{(l)}_i = A_f^{(l)}(raw^{(l)}_i) = A_f^{(l)}(W^{(l-1)}_i * out^{(l-1)} + b^{(l-1)}_i) = \n",
    "    A_f^{(l)}\\left(\\sum_k{W^{(l-1)}_{ik} out^{(l-1)}_k} + b^{(l-1)}_i\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "After the expansion, we could try to compute the derivative:\n",
    "\n",
    "$$ \\;\\;\\;\\;\\displaystyle\n",
    "\\frac{dout^{(l)}_i}{dout^{(l-1)}_j} = \n",
    "    A_f'^{(l)}\\left(\\sum_k{W^{(l-1)}_{ik} out^{(l-1)}_k} + b^{(l-1)}_i\\right) \\cdot \\frac{d\\left(\\sum_k{W^{(l-1)}_{ik} out^{(l-1)}_k} + b^{(l-1)}_i\\right)}{dout^{(l-1)}_j}\n",
    "$$\n",
    "\n",
    "\n",
    "Recalling that $ A_f'^{(l)} $ is by definition $ A_d^{(l)} $, and the previous sum derivative expansion (in section dC/dy), we would get:\n",
    "\n",
    "$$ \\;\\;\\;\\;\\displaystyle \\large\n",
    "\\frac{dout^{(l)}_i}{dout^{(l-1)}_j} = A_d^{(l)}(raw^{(l)}_i) \\cdot W^{(l-1)}_{ij};\n",
    "$$\n",
    "<div></div>\n",
    "\n",
    "$$ \\displaystyle\n",
    "\\frac{dC}{dout^{(l-1)}_i} = \n",
    "    \\sum_k{ \\left(\n",
    "        \\frac{dC}{dout^{(l)}_k} \\cdot \\frac{dout^{(l)}_k}{dout^{(l-1)}_i}\n",
    "    \\right) } = \n",
    "    \\left(\\frac{dC}{dout^{(l)}}\\right)^T * (A_d^{(l)}(raw^{(l)}) W^{(l-1)}_{*i})\n",
    "$$\n",
    "\n",
    "And this would be our final formula to find the derivative for next layer :\n",
    "$$ \\displaystyle\n",
    "\\frac{dC}{dout^{(l-1)}} = \\left(\\frac{dC}{dout^{(l)}}\\right)^T * (out^{(l)} W^{(l-1)});\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dC/dW\n",
    "\n",
    "$ \\displaystyle\n",
    "out^{(l)}_i = A_f^{(l)}(raw^{(l)}_i) = \n",
    "    A_f^{(l)}(\\sum_k{W^{(l)}_{ik} out^{(l-1)}_k} + b^{(l)}_i)\n",
    "$\n",
    "\n",
    "$ \\displaystyle\n",
    "\\frac{dout^{(l)}_i}{dW^{(l)}_{ij}} = A_d^{(l)}(\\sum_k{W^{(l)}_{ik} out^{(l-1)}_k} + b^{(l)}_i) * \\frac{d(\\sum_k{W^{(l)}_{ik} out^{(l-1)}_k} + b^{(l)}_i)}{dW^{(l)}_{ij}}\n",
    "$\n",
    "\n",
    "$ \\displaystyle\n",
    "\\frac{dout^{(l)}_i}{dW^{(l)}_{ij}} = A_d^{(l)}(raw^{(l)}_i) * out^{(l-1)}_j\n",
    "$\n",
    "\n",
    "$ \\displaystyle\n",
    "\\frac{dC}{dW^{(l)}_{ij}} = \\frac{dC}{dout^{(l)}_i} * \\frac{dout^{(l)}_i}{dW^{(l)}_{ij}} =\n",
    "    \\frac{dC}{dout^{(l)}_i} * A_d^{(l)}(raw^{(l)}_i) * out^{(l-1)}_j\n",
    "$\n",
    "\n",
    "$ \\displaystyle\n",
    "\\frac{dC}{dW^{(l)}} = (\\frac{dC}{dout^{(l)}} A_d^{(l)}(raw^{(l)})) * out^{(l-1)};\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(model: Model, x: np.ndarray) -> tuple[npt.NDArray[npt.NDArray], npt.NDArray[npt.NDArray]]:\n",
    "    a, w, b = model.a, model.w, model.b\n",
    "    raw = np.empty(model.L, dtype=object)\n",
    "    out = np.empty(model.L, dtype=object)\n",
    "    out[0] = x\n",
    "    for l in range(1, len(model.shape)):\n",
    "        raw[l] = (out[l-1] @ w[l-1] + b[l-1])\n",
    "        out[l] = a[l-1].f(raw[l])\n",
    "    return raw, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(\n",
    "    model: Model,\n",
    "    raw: list[np.ndarray],\n",
    "    out: list[np.ndarray],\n",
    "    y: np.ndarray\n",
    ") -> tuple[float, npt.NDArray[npt.NDArray], npt.NDArray[npt.NDArray]]:\n",
    "\n",
    "    L, a, w, b = model.L, model.a, model.w, model.b\n",
    "    dw = np.empty_like(w)\n",
    "    db = np.empty_like(b)\n",
    "    dCout = 2*(out[L-1] - y)\n",
    "    for l in range(L-1, 0, -1):\n",
    "        buff = dCout * a[l-1].d(raw[l])\n",
    "        dw[l-1] = out[l-1].reshape(-1, 1) @ buff.reshape(1, -1)\n",
    "        db[l-1] = buff\n",
    "        dCout = (out[l] * w[l-1]) @ dCout\n",
    "    return sum((out[L-1] - y)**2), dw, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "label    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model((784, 100, 10), [Functions.relu, Functions.sigmoid])\n",
    "model.w[0] *= .1\n",
    "model.w[1] *= .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.99999988892357\n",
      "0.9394311566062503\n",
      "0.9074389237458182\n",
      "0.8278303045262583\n",
      "0.7319894383119204\n",
      "0.641862721604982\n",
      "0.33202880211742203\n",
      "0.3617244635725242\n",
      "0.19864698329556413\n",
      "0.4451261324561845\n",
      "0.36029944185931123\n",
      "0.26645289661739074\n",
      "0.15521358695902424\n",
      "0.2556115395783608\n",
      "0.26779546123358705\n",
      "0.35802780488390573\n",
      "0.12377818055779484\n",
      "0.11640818295614366\n",
      "0.2260164857466874\n",
      "0.15035002927106897\n",
      "0.24278729179992378\n",
      "0.2899246835552123\n",
      "0.07054283673823174\n",
      "0.11596734871389783\n",
      "0.05173635931973809\n",
      "0.12570438215438964\n",
      "0.044773102011415405\n",
      "0.13448385226292037\n",
      "0.10835487527197078\n",
      "0.10928003590121001\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "for j in range(int(3e3)):\n",
    "    C, Dw, Db = 0, [0, 0], [0, 0]\n",
    "    for i in np.random.randint(0, len(ds_train), batch_size):\n",
    "        x, y = ds_train.iloc[i]\n",
    "        raw, out = forward(model, x)\n",
    "        c, dw, db = backward(model, raw, out, y)\n",
    "        C += c\n",
    "        for i in range(len(model.shape)-1):\n",
    "            Dw[i] += dw[i]\n",
    "            Db[i] += db[i]\n",
    "    if not j % int(1e2):\n",
    "        print(C / batch_size)\n",
    "    for i in range(len(model.shape)-1):\n",
    "        model.w[i] -= Dw[i] * .1 / batch_size\n",
    "        model.b[i] -= Db[i] * .01 / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find image with error 0.1, 2 steps needed.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = 0\n",
    "counter = 0\n",
    "error_to_find = 0.1\n",
    "while c < error_to_find or not counter:\n",
    "    x, y = ds_test.iloc[rnd.randint(0, len(ds_test)-1)]\n",
    "    pred = forward(model, x)[1][-1]\n",
    "    c = sum((pred - y)**2)\n",
    "    counter += 1\n",
    "(fig, [ax1, ax2]) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "ax1.imshow(x.reshape(28, -1))\n",
    "ax2.plot(y)\n",
    "ax2.plot(pred)\n",
    "print(f\"To find image with error {error_to_find}, {counter} steps needed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e557ea5211ede434a26f80b7971e1d02d8d12808ee0bdf1820797eb4c67a1df1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
